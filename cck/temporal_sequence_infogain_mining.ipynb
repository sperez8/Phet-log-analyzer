{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "from functions import *\n",
    "from mining_functions import *\n",
    "from collections import Counter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "# %matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = '/Google Drive/Jonathan Sarah Ido folder/data/CCK/'\n",
    "def get_path(path = PATH):\n",
    "    if os.name == 'posix':\n",
    "        return os.environ['HOME']+path #'/Google Drive/Jonathan Sarah Ido folder/data/CCK/'\n",
    "    elif os.name == 'nt':\n",
    "        return os.environ['USERPROFILE']+ path.replace('/','\\\\') #'\\\\Google Drive\\Jonathan Sarah Ido folder\\data\\CCK\\\\'\n",
    "    else:\n",
    "        raise Exception('OS not recongnized. I\\'m confused.')\n",
    "gitpath = '/Documents/git/Phet-log-analyzer/cck/raw_data_parsing_check/'\n",
    "df = pd.read_csv(get_path(path = gitpath) + 'phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt',index_col=False)\n",
    "# dfx = pd.read_csv('C:\\Users\\Sarah\\Documents\\git\\Phet-log-analyzer\\cck\\\\raw_data_parsing_check\\phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt',index_col=False)\n",
    "df[\"student\"] = df[\"student\"].astype('category')\n",
    "df[\"Family\"]=df[\"Family\"].str.capitalize()\n",
    "df[\"Family_tool\"]=df[\"Family_tool\"].str.capitalize()\n",
    "df[\"Family_default\"]=df[\"Family_default\"].str.capitalize()\n",
    "df[\"Family_both\"]=df[\"Family_both\"].str.capitalize()\n",
    "\n",
    "df_scores = pd.read_csv(data_path + 'MATCHING_phet_cck_user_data_anonymized.txt')\n",
    "df_scores[\"student\"] = df_scores[\"student\"].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used to calculate information gain, plot use, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_infogain(data,B,axesnum=None):\n",
    "    ''' \n",
    "    This function calculates the information gain of 2D numpy array. By default, it does not ignore one of the axis.\n",
    "    \n",
    "    Arguments:\n",
    "    data: 2D numpy array\n",
    "    axesnum: By default, will calculate cumulative information gain over both axes.  \n",
    "    If 0, then information gain along axis=0 of data is calculated, i.e. for arrangement over time segments over all groups\n",
    "    If 1, then information gain for arrangement over groups over all time is calculated.\n",
    "    '''\n",
    "    max_order_data = np.array([[1.0 for i in range(B)] for j in range(2)])\n",
    "    entropy = calc_entropy(data,axesnum)\n",
    "    if axesnum == 0 or axesnum == 1:\n",
    "        max_entropy = calc_entropy(max_order_data,axesnum)\n",
    "        infogain = max_entropy - entropy\n",
    "        if infogain >= 0:\n",
    "            return infogain\n",
    "        else:\n",
    "            raise Exception(\"Negative infogain.\")\n",
    "    elif axesnum == None:\n",
    "        max_entropy = calc_entropy(max_order_data)\n",
    "        infogain = max_entropy - entropy\n",
    "        if infogain >= 0:\n",
    "            return infogain\n",
    "        else:\n",
    "            raise Exception(\"Negative infogain.\")\n",
    "    else:\n",
    "        raise Exception(\"Invalid value for argument: axesnum can be 0,1 or None \")\n",
    "\n",
    "        \n",
    "def plot_heat_map(data, title, ylabels, DisplayXProb = True, DisplayYProb = True, show_cbar=True):\n",
    "\n",
    "    ''' \n",
    "    This function plots a heat map given a 2D numpy array.  The array elements relate \n",
    "    to the amount of times a certain sequence of actions is used by students belonging to a \n",
    "    certain group at a certain time segment of their activity.\n",
    "    \n",
    "    Arguments:\n",
    "    data: 2D numpy array (data.shape = n*m, where n is len(ylabels) and m is whatever time segment resolution used)\n",
    "    \n",
    "    ylabels: list of strings to label the y-axis of heat-map (i.e. the 2 student groups compared)\n",
    "    By default plot_heat_map will also display the probabilities used in entropy calc corresponding\n",
    "    to each row and column of data array (on the side of the plot opposite the x/ylabels).\n",
    "    i.e. probabilities that sequence is used by a certain group over all time \n",
    "    and probabilities that sequence is used for a certain time segment over all groups \n",
    "    \n",
    "    show_cbar: show colorbar to the left of plot\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "    #set title\n",
    "    ax.set_title(title,y=1,loc='left',fontsize=14)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_yticks(np.arange(data.shape[0]) + 0.5)\n",
    "    ax.set_xticks(np.arange(data.shape[1]) + 0.5)\n",
    "\n",
    "    # Set the labels\n",
    "    xlabels = map(str, np.arange(data.shape[1])+1) \n",
    "#     ax.set_xticklabels(xlabels, fontweight='bold')\n",
    "    ax.set_xticklabels([],)\n",
    "    ax.set_yticklabels(ylabels, fontweight='bold')\n",
    "\n",
    "    # Create new axes that will show probability that sequence is used by a certain group over all time \n",
    "    total = np.sum(data).astype(float) #total number of students that used sequence\n",
    "    if DisplayXProb == True:\n",
    "        probx = np.sum(data, axis=0)/total\n",
    "        xlabels2 = list(\"%.2f\" % px for px in probx)\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.xaxis.tick_bottom()\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_frame_on(False)\n",
    "        ax2.set_xlim(ax.get_xlim())\n",
    "        ax2.set_xticks(np.arange(data.shape[1]) + 0.5)\n",
    "        ax2.set_xticklabels(xlabels2)\n",
    "        ax2.tick_params(\n",
    "            axis='x',           # changes apply to both the x and y-axis\n",
    "            which='both',       # both major and minor ticks are affected\n",
    "            bottom='off',       # ticks along the those edges are off\n",
    "            top='off') \n",
    "\n",
    "    # Create new axes that will show probability that sequence is used for a certain time segment over all groups \n",
    "    if DisplayYProb == True:\n",
    "        proby = np.sum(data, axis=1)/total\n",
    "        ylabels3 = list(\"%.2f\" % py for py in proby)\n",
    "        ax3 = ax.twinx()\n",
    "        ax3.set_frame_on(False)\n",
    "        ax3.set_ylim(ax.get_ylim())\n",
    "        ax3.set_yticks(np.arange(data.shape[0]) + 0.5)\n",
    "        ax3.set_yticklabels(ylabels3)\t\n",
    "        ax3.tick_params(\n",
    "            axis='y',           # changes apply to both the x and y-axis\n",
    "            which='both',       # both major and minor ticks are affected\n",
    "            right='off',        # ticks along the those edges are off\n",
    "            left='off') \n",
    "\n",
    "    # put time labels on top\n",
    "    ax.xaxis.tick_top()\n",
    "    # figure size \n",
    "    fig.set_size_inches(8, 2)\n",
    "    # turn off the frame\n",
    "    ax.set_frame_on(False)\n",
    "    # rotate the xticks labels if needed\n",
    "    # plt.xticks(rotation=90)\n",
    "    # Turn off all the ticks\n",
    "    ax.tick_params(\n",
    "        axis='both',        # changes apply to both the x and y-axis\n",
    "        which='both',       # both major and minor ticks are affected\n",
    "        bottom='off',       # ticks along the those edges are off\n",
    "        right='off', \n",
    "        left='off',\n",
    "        top='off') \n",
    "    \n",
    "    if show_cbar == True: # Add colorbar\n",
    "        cbaxes = fig.add_axes([1, 0.1, 0.02, 0.8])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(heatmap, cax=cbaxes)\n",
    "        cbarticks = [np.amin(data),(np.amin(data)+np.amax(data))/2,np.amax(data)]\n",
    "        cbar.set_ticks(cbarticks)\n",
    "        cbar.set_ticklabels(map(str, cbarticks))\n",
    "    return fig\n",
    "\n",
    "def add_text(attribute,family_category,N, shortest_seq_length, longest_seq_length,B):\n",
    "    text = \"\"\"Showing sequences for students split by {0}, using the categories {1}.\n",
    "            Removed sequences used by less than {2}.\n",
    "            Found sequences of lenght {3} to {4}.\n",
    "            Using {5} time bins\"\"\".format(attribute,family_category,N, shortest_seq_length, longest_seq_length,B)\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.5,0.5,text,\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center',\n",
    "        fontsize = 15)\n",
    "    plt.axis('off')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_sequences(sequence_counts,B,axesnum=None):\n",
    "    ranks = []\n",
    "    for seq,counts in sequence_counts.iteritems():\n",
    "#         if np.sum(counts)>0:\n",
    "        ranks.append((seq,calc_infogain(counts,B,axesnum)))\n",
    "    return sorted(ranks, key=lambda tup: tup[1])\n",
    "\n",
    "def get_top_seqs(ranks,N):\n",
    "    return ranks[-N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we get the raw count of unique students using a sequence per time bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wave', 'scaffolding', 'how many PhETs in the past?', 'how comfortable with phets?', 'p100', 'used this circuit sim before?', 'COMPLETEDNESS', 'PRIORKNOWLEDGE', 'COMPLEXITY', 'DIAGRAMS', 'NUMBERSANDCALCULATIONSONLYINATLEASTONEANSWER', 'pre', 'post t1', 'post t2', 'post identical to pre', 'z post identical to pre', 'z pre', 'z post t1', 'z post t2', 'T0_PoCC', 'T1_PoCC', 'T2_PoCC', 'Avg_Mast_Or', 'Perceived Value ', 'Clustergroups', 'fourgroups', 'student', 'Anon Student Id', 'incoming_knowledge', 'incoming_attitude']\n"
     ]
    }
   ],
   "source": [
    "print list(df_scores.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_learning (median,row,column):\n",
    "    if row[column] >= median: return 'high'\n",
    "    else: return 'low'\n",
    "\n",
    "median_pre = np.median(df_scores['pre'])\n",
    "df_scores['incoming_knowledge'] = df_scores.apply (lambda row: label_learning (median_pre,row,\"pre\"),axis=1)\n",
    "\n",
    "median_T0_PoCC = np.median(df_scores['T0_PoCC'])\n",
    "df_scores['incoming_attitude'] = df_scores.apply (lambda row: label_learning (median_T0_PoCC,row,\"T0_PoCC\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "students = get_students()\n",
    "CUT_OFF_SEQ_USE = 0.2 #we keep only sequences used once by at least 10% of students\n",
    "N = int(CUT_OFF_SEQ_USE*len(students))\n",
    "shortest_seq_length = 3\n",
    "longest_seq_length = 12\n",
    "B = 5  #number of bins\n",
    "\n",
    "### PARAMETERS\n",
    "# attributes = [('learning2','high', 'low'),('scaffolding','scaff', 'not'),('incoming_knowledge','high', 'low'),('incoming_attitude','high', 'low')]\n",
    "# attribute, level1, level2 = 'learning2','high', 'low'\n",
    "# attribute, level1, level2 = 'scaffolding','scaff', 'not'\n",
    "attributes = [('incoming_knowledge','high', 'low')]\n",
    "# attribute, level1, level2 = 'incoming_attitude','high', 'low'\n",
    "\n",
    "family_categories = [\"Family\"]#,\"Family_tool\",\"Family_default\",\"Family_both\"]\n",
    "\n",
    "# sequence_counts = get_sequence_use_by_timebin(df,students,family_category,B,attribute,level1,level2,shortest_seq_length,longest_seq_length,N)\n",
    "# for k,v in sequence_counts.iteritems():\n",
    "#     print k,v, np.sum(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We can calculate the information gain of each sequence by time bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For attribute incoming_knowledge, categories Family\n",
      "Getting sequence use over 5 time bins for 96 students split by incoming_knowledge. \n",
      "            Keeping only sequences used once by at least 19 students.\n"
     ]
    }
   ],
   "source": [
    "parse_axis = {0:'time',1:'group',None:'time and group'}\n",
    "\n",
    "pdf = PdfPages('infogain_results.pdf')\n",
    "\n",
    "for attribute,level1,level2 in attributes:\n",
    "    for family_category in family_categories:\n",
    "        print \"For attribute {0}, categories {1}\".format(attribute,family_category)\n",
    "        pdf.savefig(add_text(attribute,family_category,N, shortest_seq_length, longest_seq_length,B))\n",
    "        sequence_counts = get_sequence_use_by_timebin(df,students,family_category,B,attribute,level1,level2,shortest_seq_length,longest_seq_length,N)\n",
    "        ylabels = [level1,level2]\n",
    "        for axis in [0,1,None]:\n",
    "            tops = get_top_seqs(rank_sequences(sequence_counts,B,axis),1)\n",
    "            for seq,infogain in tops:\n",
    "                title = '{0}: infogain {1} by {2}'.format(seq,round(infogain,3),parse_axis[axis])\n",
    "                pdf.savefig( plot_heat_map(sequence_counts[seq],title, ylabels) )\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
