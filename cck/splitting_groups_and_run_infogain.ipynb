{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "from functions import *\n",
    "from mining_functions import *\n",
    "from collections import Counter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('precision', 2)\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File C:\\Users\\Sarah\\git\\Phet-log-analyzer\\cck\\raw_data_parsing_check\\phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4805fd31e080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgitpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/git/Phet-log-analyzer/cck/raw_data_parsing_check/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgitpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# dfx = pd.read_csv('C:\\Users\\Sarah\\Documents\\git\\Phet-log-analyzer\\cck\\\\raw_data_parsing_check\\phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt',index_col=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"student\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"student\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    527\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Sarah\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File C:\\Users\\Sarah\\git\\Phet-log-analyzer\\cck\\raw_data_parsing_check\\phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt does not exist"
     ]
    }
   ],
   "source": [
    "PATH = '/Google Drive/Jonathan Sarah Ido folder/data/CCK/'\n",
    "def get_path(path = PATH):\n",
    "    if os.name == 'posix':\n",
    "        path = '/Documents/code/Phet-log-analyzer/cck/raw_data_parsing_check/'\n",
    "        return os.environ['HOME']+path #'/Google Drive/Jonathan Sarah Ido folder/data/CCK/'\n",
    "    elif os.name == 'nt':\n",
    "        if os.getenv(\"COMPUTERNAME\") == 'PYRRHA':\n",
    "                path = '/Documents/git/Phet-log-analyzer/cck/raw_data_parsing_check/'\n",
    "        else:\n",
    "            path = '/git/Phet-log-analyzer/cck/raw_data_parsing_check/'\n",
    "        return os.environ['USERPROFILE']+ path.replace('/','\\\\') #'\\\\Google Drive\\Jonathan Sarah Ido folder\\data\\CCK\\\\'\n",
    "    else:\n",
    "        raise Exception('OS not recongnized. I\\'m confused.')\n",
    "        \n",
    "df = pd.read_csv(get_path() + 'phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt',index_col=False)\n",
    "# dfx = pd.read_csv('C:\\Users\\Sarah\\Documents\\git\\Phet-log-analyzer\\cck\\\\raw_data_parsing_check\\phet_cck_user_actions+sophistication_WITHPAUSE_more_circuit_info.txt',index_col=False)\n",
    "df[\"student\"] = df[\"student\"].astype('category')\n",
    "df[\"Family\"]=df[\"Family\"].str.capitalize()\n",
    "df[\"Family_tool\"]=df[\"Family_tool\"].str.capitalize()\n",
    "df[\"Family_default\"]=df[\"Family_default\"].str.capitalize()\n",
    "df[\"Family_both\"]=df[\"Family_both\"].str.capitalize()\n",
    "\n",
    "df_scores = pd.read_csv(data_path + 'MATCHING_phet_cck_user_data_anonymized.txt')\n",
    "df_scores[\"student\"] = df_scores[\"student\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_time = 25*60*1000\n",
    "max_times = {s:min(df[df['student']==s][\"Time Stamp\"])+max_time for s in set(df['student'])}\n",
    "\n",
    "def keep_by_time (row):\n",
    "    if row[\"Time Stamp\"] <= max_times[row[\"student\"]]:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "df['keep'] = df.apply (lambda row: keep_by_time (row),axis=1)\n",
    "df=df[df['keep']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used to calculate information gain, plot use, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_text(attribute,family_category,cut_off, shortest_seq_length, longest_seq_length,B):\n",
    "    text = \"\"\"Showing sequences for students split by {0}, using the categories {1}.\n",
    "            Removed sequences used by less than {2}% of students.\n",
    "            Found sequences of lenght {3} to {4}.\n",
    "            Using {5} time bins\"\"\".format(attribute,family_category,int(cut_off*100), shortest_seq_length, longest_seq_length,B)\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.5,0.5,text,\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center',\n",
    "        fontsize = 15)\n",
    "    plt.axis('off')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank_sequences(sequence_counts,B,axesnum=None):\n",
    "    ranks = []\n",
    "    for seq,counts in sequence_counts.iteritems():\n",
    "#         if np.sum(counts)>0:\n",
    "        ranks.append((seq,calc_infogain(counts,B,axesnum)))\n",
    "    return sorted(ranks, key=lambda tup: tup[1])\n",
    "\n",
    "def get_top_seqs(ranks,N):\n",
    "    return ranks[-N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's investigate how best to split students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_scores.hist(column='z pre')\n",
    "# print list(df_scores['z pre'])\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "fig, ax = plt.subplots(1, figsize=(5.5,2.5))\n",
    "sns.distplot(list([x for x in df_scores['z pre'] if x <= 0.45]), \n",
    "             bins=7, kde=False, rug=False, color='#3f007d', hist_kws={'alpha':0.7}, label = 'low incoming knowledge');\n",
    "X = list([x for x in df_scores['z pre'] if x > 0.45])\n",
    "X.extend([2.45,2.45,2.45])\n",
    "sns.distplot(X,bins=3, kde=False, rug=False, color='#525252', hist_kws={'alpha':0.7},  label = 'high incoming knowledge');\n",
    "ax.set_ylabel('Number of students')\n",
    "ax.set_xlabel('pre-test z-score')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd = ax.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.0,0.95))\n",
    "fig.savefig('figs/hist_pre.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clearly, students' pre test is a bi modal distribution. Let's split them this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_learning0 = 0.45\n",
    "df_scores['split pre'] = df_scores.apply (lambda row: label_learning (median_learning0,row,\"z pre\"),axis=1)\n",
    "median_learning2 = np.median(df_scores[df_scores['split pre']=='low']['z post t2'])\n",
    "df_scores['split post t2'] = df_scores.apply (lambda row: label_learning (median_learning2,row,\"z post t2\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in ['high','low']:\n",
    "    for y in ['high','low']:\n",
    "        print x,y, len(set(df_scores[(df_scores['split pre']==x)&(df_scores['split post t2']==y)]['student']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #making student ids groups csv file for Lauren\n",
    "# for x in ['high','low']:\n",
    "#     for y in ['high','low']:\n",
    "#         for z in list(set(df_scores[(df_scores['split pre']==x)&(df_scores['split post t2']==y)]['student'])):\n",
    "#             print str(z)+','+x+'-'+y\n",
    "# #         print x,y, len(set(df_scores[(df_scores['split pre']==x)&(df_scores['split post t2']==y)]['student']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in ['high','low']:\n",
    "    for y in ['scaff','not']:\n",
    "        print x,y, len(set(df_scores[(df_scores['scaffolding']==y)&(df_scores['split pre']==x)]['student']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in ['high','low']:\n",
    "    for y in ['scaff','not']:\n",
    "        print x,y, len(set(df_scores[(df_scores['scaffolding']==y)&(df_scores[df_scores['split pre']=='low']['split post t2']==x)]['student']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = set(get_students('split post t2','high'))\n",
    "b = set(get_students('used this circuit sim before?',1))\n",
    "c = set(get_students('split post t2','low'))\n",
    "print len(a), len(b), len(a.intersection(b)), len(c.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = df_scores[df_scores['split pre']=='low']['z pre']\n",
    "y = df_scores[df_scores['split pre']=='high']['z pre']\n",
    "print np.mean(z), np.std(z)\n",
    "print np.mean(y), np.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_learning2 = np.median(df_scores[df_scores['split pre']=='low']['z post t2'])\n",
    "fig, ax = plt.subplots(1, figsize=(5.5,2.5))\n",
    "sns.axes_style({'legend.numpoints': 20})\n",
    "ax.set_ylim(0,13)\n",
    "bar1 = sns.distplot(list([x for x in df_scores[df_scores['split pre']=='low']['z post t2'] if x <= median_learning2]), \n",
    "             bins=5, kde=False, rug=False, color='#3f007d', hist_kws={'alpha':0.7},  label = 'Low-Low learners');\n",
    "bar2 = sns.distplot(list([x for x in df_scores[df_scores['split pre']=='low']['z post t2'] if x > median_learning2]), \n",
    "             bins=6, kde=False, rug=False, color='#3f007d', hist_kws={'alpha':0.7}, label = 'Low-High learners');\n",
    "# Define some hatches\n",
    "hatches = ['-', '+', 'x', '\\\\', '*', 'o','-', '+', 'x', '\\\\', '*', 'o']\n",
    "# Loop over the bars\n",
    "for i,thisbar in enumerate(bar1.patches):\n",
    "    if i <=4:\n",
    "    # Set a different hatch for each bar\n",
    "        thisbar.set_hatch(hatches[5])\n",
    "    else:\n",
    "        thisbar.set_hatch(hatches[2])\n",
    "ax.set_xlabel('post-test z-score')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd = ax.legend(handles, labels, loc='upper right', bbox_to_anchor=(.95,0.95))\n",
    "fig.savefig('figs/hist_post.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "print st.pearsonr(df_scores[df_scores['split pre']=='low'][\"z pre\"],df_scores[df_scores['split pre']=='low'][\"z post t2\"] )\n",
    "print st.spearmanr(df_scores[df_scores['split pre']=='low'][\"z pre\"],df_scores[df_scores['split pre']=='low'][\"z post t2\"] )\n",
    "plt.plot(df_scores[df_scores['split pre']=='low'][\"z pre\"],df_scores[df_scores['split pre']=='low'][\"z post t2\"],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#making student ids groups csv file for Lauren\n",
    "for x in ['high','low']:\n",
    "        print x, 'm', np.mean(list(df_scores[(df_scores['split pre']==x)]['pre']))\n",
    "        print x,'s', np.std(list(df_scores[(df_scores['split pre']==x)]['post t2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_same = list(df_scores['pre'])\n",
    "post_same = list(df_scores['post identical to pre'])\n",
    "print len(pre_same)\n",
    "print np.mean(pre_same),np.mean(post_same)\n",
    "print np.std(pre_same),np.std(post_same)\n",
    "t,p =  stats.ttest_ind(post_same,pre_same,equal_var=False)\n",
    "print t,p\n",
    "d = (np.mean(post_same)-np.mean(pre_same))/math.sqrt((np.std(pre_same)**2+np.std(post_same)**2)/2)\n",
    "print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can calculate the information gain of each sequence by time bin \n",
    "given a split by pre test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### if redoing this analysis, fix algorithm wot use frequency of use in each time bin because we have unequal groups\n",
    "\n",
    "# students = get_students()\n",
    "# CUT_OFF = 0.35 #we keep only sequences used once by at least 20% of students\n",
    "# shortest_seq_length = 2\n",
    "# longest_seq_length = 10\n",
    "# BINS = 4  #number of bins\n",
    "\n",
    "# ### PARAMETERS\n",
    "# attributes = [('split pre','high','low')]\n",
    "# family_categories = [\"Family\",\"Family_tool\",\"Family_default\"]\n",
    "\n",
    "# parse_axis = {0:'time',1:'group',None:'time and group'}\n",
    "# pdf = PdfPages('infogain_results_by_pre.pdf')\n",
    "\n",
    "# for attribute,level1,level2 in attributes:\n",
    "#     for family_category in family_categories:\n",
    "#         for axis in [0,1,None]:\n",
    "#             if axis == 1: B = 1\n",
    "#             else: B = BINS\n",
    "        \n",
    "#             print \"For attribute {0}, category {1}\".format(attribute,family_category)\n",
    "#             pdf.savefig(add_text(attribute,family_category,CUT_OFF, shortest_seq_length, longest_seq_length,B))\n",
    "#             sequence_counts = get_sequence_use_by_timebin(df,students,family_category,\n",
    "#                                                           B,attribute,level1,level2,\n",
    "#                                                           shortest_seq_length,longest_seq_length,CUT_OFF)\n",
    "#             print len(sequence_counts)\n",
    "#             ylabels = [level1,level2]\n",
    "#             tops = get_top_seqs(rank_sequences(sequence_counts,B,axis),5)\n",
    "#             for seq,infogain in tops:\n",
    "# #                 print seq, sequence_counts[seq]\n",
    "#                 title = '{0}: infogain {1} by {2}'.format(seq,round(infogain,3),parse_axis[axis])\n",
    "#                 plot = plot_heat_map(sequence_counts[seq],title, ylabels)\n",
    "#                 pdf.savefig( plot )\n",
    "#                 plot.clf()\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can calculate the information gain of each sequence by time bin \n",
    "given a split by post test, for only students that did poorly on pre test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "students = get_students(attribute='split pre',level='low')\n",
    "CUT_OFF = 0.35 #we keep only sequences used once by at least 10% of students\n",
    "shortest_seq_length = 2\n",
    "longest_seq_length = 10\n",
    "BINS = 4  #number of bins\n",
    "\n",
    "### PARAMETERS\n",
    "attributes = [('split post t2','high','low')]\n",
    "family_categories = [\"Family\"]#,\"Family_tool\",\"Family_default\"]\n",
    "\n",
    "parse_axis = {0:'time',1:'group',None:'time and group'}\n",
    "pdf = PdfPages('infogain_results_by_post2.pdf')\n",
    "\n",
    "for attribute,level1,level2 in attributes:\n",
    "    for family_category in family_categories:\n",
    "        for axis in [0,1,None]:\n",
    "            if axis == 1: B = 1\n",
    "            else: B = BINS\n",
    "        \n",
    "            print \"For attribute {0}, categories {1}\".format(attribute,family_category)\n",
    "            pdf.savefig(add_text(attribute,family_category,CUT_OFF, shortest_seq_length, longest_seq_length,B))\n",
    "            sequence_counts = get_sequence_use_by_timebin(df,students,family_category,\n",
    "                                                          B,attribute,level1,level2,\n",
    "                                                          shortest_seq_length,longest_seq_length,CUT_OFF)\n",
    "            ylabels = [level1,level2]\n",
    "            tops = get_top_seqs(rank_sequences(sequence_counts,B,axis),15)\n",
    "#             print parse_axis[axis]\n",
    "            for seq,infogain in tops:\n",
    "#                 print seq, infogain\n",
    "                title = '{0}: infogain {1} by {2}'.format(seq,round(infogain,3),parse_axis[axis])\n",
    "                plot = plot_heat_map(sequence_counts[seq],title, ylabels)\n",
    "                pdf.savefig( plot )\n",
    "                plot.clf()\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We repeat the same analysis, only remove the first time bin before to see if what students do in other time bins differentiates them as well (though not as significantly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parse_axis = {0:'time',1:'group',None:'time and group'}\n",
    "\n",
    "# pdf = PdfPages('infogain_results_no_first_bin.pdf')\n",
    "\n",
    "# for attribute,level1,level2 in attributes:\n",
    "#     for family_category in family_categories:\n",
    "#         for axis in [0,1,None]:\n",
    "#             if axis == 1:\n",
    "#                 B = 1\n",
    "#             else:\n",
    "#                 B = 3\n",
    "        \n",
    "#             print \"For attribute {0}, categories {1}\".format(attribute,family_category)\n",
    "#             pdf.savefig(add_text(attribute,family_category,N, shortest_seq_length, longest_seq_length,B))\n",
    "#             sequence_counts = get_sequence_use_by_timebin(df,students,family_category,B,attribute,level1,level2,shortest_seq_length,longest_seq_length,N)\n",
    "#             sequence_counts = remove_first_bin(sequence_counts)\n",
    "#             ylabels = [level1,level2]\n",
    "#             tops = get_top_seqs(rank_sequences(sequence_counts,B,axis),1)\n",
    "#             for seq,infogain in tops:\n",
    "#                 print seq, sequence_counts[seq]\n",
    "#                 title = '{0}: infogain {1} by {2}'.format(seq,round(infogain,3),parse_axis[axis])\n",
    "#                 plot = plot_heat_map(sequence_counts[seq],title, ylabels)\n",
    "#                 pdf.savefig( plot )\n",
    "#                 plot.clf()\n",
    "# pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def remove_first_bin(sequence_counts):\n",
    "#     new_seq_counts = {}\n",
    "#     for s,c in sequence_counts.iteritems():\n",
    "#         new_seq_counts[s] = c[:,1:]\n",
    "#     return new_seq_counts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "students = get_students(attribute='split pre',level='low')\n",
    "CUT_OFF = 0.35 #we keep only sequences used once by at least 35% of students\n",
    "shortest_seq_length = 2\n",
    "longest_seq_length = 10\n",
    "B = 1  #number of bins\n",
    "\n",
    "### PARAMETERS\n",
    "attribute, level1, level2 = ('split post t2','high','low')\n",
    "family_category = \"Family\"\n",
    "sequence_counts = get_sequence_use_by_timebin(df,students,family_category,\n",
    "                                                          B,attribute,level1,level2,\n",
    "                                                          shortest_seq_length,longest_seq_length,CUT_OFF)\n",
    "print len(set(sequence_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tops = get_top_seqs(rank_sequences(sequence_counts,1,1),10)\n",
    "print tops\n",
    "tops.sort(key=lambda tup: tup[1],reverse=True)\n",
    "tops.append(('CPTb',1.275))\n",
    "tops.append(('CTbCP',1.073))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "table = [['rank','seq','infogain','lh','ll','chi2','p','chi2 new','p new','fisher\\'s p']]\n",
    "for i,(seq,infogain) in enumerate(tops):\n",
    "    i = i+1\n",
    "    lh = int(sequence_counts[seq][0])\n",
    "    ll = int(sequence_counts[seq][1])\n",
    "    nlh = 38-lh\n",
    "    nll = 36-ll\n",
    "    obs = [[lh,ll],[nlh,nll]]\n",
    "    \n",
    "    total = float(lh + nlh + ll + nll)\n",
    "    result = stats.chisquare(f_obs= [lh,ll],   # Array of observed counts\n",
    "                    f_exp= [(lh+nlh)*(lh+ll)/total,(ll+nll)*(lh+ll)/total])   # Array of expected counts\n",
    "    c2 = result.statistic\n",
    "    p = result.pvalue\n",
    "    C2,P,_,_ =  stats.chi2_contingency(obs, correction=False)\n",
    "    _,fp = stats.fisher_exact(obs)\n",
    "    table.append([str(x) for x in [i,seq, round(infogain,3),lh,ll,round(c2,3),round(p,3),round(C2,3),round(P,3),round(fp,3)]])\n",
    "print tabulate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "students = get_students(attribute='split pre',level='low')\n",
    "CUT_OFF = 0.35 #we keep only sequences used once by at least 35% of students\n",
    "shortest_seq_length = 2\n",
    "longest_seq_length = 10\n",
    "B = 4  #number of bins\n",
    "\n",
    "### PARAMETERS\n",
    "attribute, level1, level2 = ('split post t2','high','low')\n",
    "family_category = \"Family\"\n",
    "sequence_counts = get_sequence_use_by_timebin(df,students,family_category,\n",
    "                                                          B,attribute,level1,level2,\n",
    "                                                          shortest_seq_length,longest_seq_length,CUT_OFF)\n",
    "print len(set(sequence_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chi2 = {'PTsPC':5.580,'CTsPTsP':3.138,'CPCTsC':4.004,'TsPTsPC':3.138,\n",
    "        'PCTcCTcC':4.004,'PTsP':5.395,'PCPCTcC':3.275,'TcCPC':4.408,\n",
    "        'TsCTsC':2.973,'CPTs':2.494,'CPTb':None,'CTbCP':None}\n",
    "numbers = {'PTsPC':(20,7),  'CTsPTsP':(13,5),  'CPCTsC':(5,13), \n",
    "           'TsPTsPC':(13,5),  'PCTcCTcC':(5,13),  'PTsP':(23,9),  'PCPCTcC':(5,12), \n",
    "           'TcCPC':(8,18),  'TsCTsC':(6,13),  'CPTs':(15,7), 'CPTb':(14,10),'CTbCP':(13,9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "all_seqs = zip(*tops)[0]\n",
    "fig, axes = plt.subplots(len(all_seqs),1)#, sharex=True, sharey=True)\n",
    "maximum = int(max([np.amax(counts) for seq,counts in sequence_counts.iteritems() if seq in all_seqs]))\n",
    "for i,(seq,ig) in enumerate(tops):\n",
    "    ax = axes[i]\n",
    "    data = sequence_counts[seq]\n",
    "    chi = chi2[seq]\n",
    "    hl,ll = numbers[seq]\n",
    "    seq = \"$\"+seq.replace('Ts','T_2').replace('Tb','T_1').replace('Tc','T_m')+\"$\"\n",
    "    ax.text(0,2.05, seq, fontsize=14)\n",
    "    if chi:\n",
    "        ax.text(1.35,2.05, \"$IG$= {0}, $LL$: {1}, $LH$: {2}, $\\chi^2$= {3}\".format(str(round(ig,2)),ll,hl,round(chi,1)),\n",
    "                fontsize=10)\n",
    "    else:\n",
    "        ax.text(2.0,2.05, \"$IG$= {0}, $LL$: {1}, $LH$: {2}\".format(str(round(ig,2)),ll,hl), fontsize=10)\n",
    "\n",
    "    # heatmap = ax.pcolor(data, cmap=plt.cm.Blues, alpha=0.8, vmin=0)\n",
    "    heatmap = sns.heatmap(data, ax=ax, cmap=plt.cm.Blues,alpha=0.8, vmin=0, vmax=maximum, cbar=False,\n",
    "                          annot=False) #, annot_kws={'fontweight':'bold'})\n",
    "\n",
    "    if i==0:\n",
    "        xlabels = map(str, np.arange(data.shape[1])+1) \n",
    "        xlabels = ['1st time bin','2nd','3rd','4th']\n",
    "        ax.set_xticklabels([],)\n",
    "        ax.set_xticks(np.arange(data.shape[1]) + 0.5)\n",
    "        ax.set_xticklabels(xlabels)\n",
    "        ax.set_yticks(np.arange(data.shape[0]) + 0.5)\n",
    "        ylabels = ['Low-Low','Low-High']\n",
    "        ax.set_yticklabels(ylabels)\n",
    "\n",
    "#         cbar = ax.figure.colorbar(ax.collections[0])\n",
    "#         cbar.set_ticks([0,1,3,5,7,9,11,13])\n",
    "#         cbar.set_ticklabels([0,1,3,5,7,9,11,13])\n",
    "    else: \n",
    "        ax.set_xticklabels(['','','',''])\n",
    "        ax.set_yticklabels(['',''])\n",
    "\n",
    "        \n",
    "\n",
    "#     cbar = ax.figure.colorbar(ax.collections[0])\n",
    "#     cbar.set_ticks([0,1,3,5,7,9,11,13])\n",
    "#     cbar.set_ticklabels([0,1,3,5,7,9,11,13])\n",
    "\n",
    "    fig.set_size_inches(4,1.6*len(all_seqs))\n",
    "    ax.set_frame_on(False)\n",
    "#     ax.tick_params(\n",
    "#         axis='both',        # changes apply to both the x and y-axis\n",
    "#         which='both',       # both major and minor ticks are affected\n",
    "#         bottom='off',       # ticks along the those edges are off\n",
    "#         right='off', \n",
    "#         left='off',\n",
    "#         top='off') \n",
    "fig.savefig('figs/heatmap_all.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
